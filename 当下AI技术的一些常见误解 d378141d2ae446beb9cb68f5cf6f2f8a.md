# 当下AI技术的一些常见误解

![](https://my-image.askcheng.xyz/cheng-img/2024/07/6720cfaef1bac1514e2adb1b8ed1c4a5.png)

> 我们处在大模型技术高速发展的时代，预训练的大模型让我们所有人都可以方便高效地使用AI来提高效率，但是这个技术也存在一些理解上的误区，导致我们在真实场景下的使用存在一些问题，最终放弃了持续使用。这个技术离我们那么近，应用市场里面有那么多的AI应用我们下载了就可以免费使用，又好像离我们很远，我们如果没办法掌握一些技巧或者认知的话，又处处受阻。所以了解这个技术到底跟我们接触的各种软件有什么不一样，能帮助我们更好的适应新技术带来的新变化。
> 

# 常见的问题

- 怎么不能批量处理表格数据啊？
- 怎么不能把一本书的内容都放进去解读和提问啊？
- 怎么这么笨，最近奥运会的战况都查不到呀？
- 怎么又开始胡说了呀，明明数据就不是这样的？
- 怎么就是不识数呢，说了不超过300字，怎么就不听话？

你在刚开始有接触过一些AI产品之后是不是也会有这些疑问？或者被其他的同事朋友问到

这些问题里面包含了对于AI大模型本身技术理解上的误区，也包含了对于AI大模型和AI产品的差异的误区，我们今天就重点为讲解到底这里面有什么东西跟我们想的不一样

# AI和AI产品的区别

![](https://my-image.askcheng.xyz/cheng-img/2024/07/be6b3bdfe3cd948082150740ae16e2d9.png)

AI：主要是指的大模型本身，这些模型被使用的的方式是API，这些大模型首先被各个厂商训练出来，然后被部署到具体的算力机器上，前期的训练过程也是在海量的机器上进行的，这个过程叫**训练**。训练之后这些默认会变成具体的文件，然后被部署到一些机器上，通过API的方式对外提供服务，这个过程叫做**推理。使用AI的人是模型的开发厂商和一些应用开发人员，实现的是模型本身的基础的能力。**（这个能力到底是是什么，我们放到第二部分讲）

AI产品：这是我们日常用户用到的实际的AI产品，比如chatGPT、文心一言、kimichat等等，这些产品都是模型厂商基于模型的能力进行了一些工程化的封装之后给到大众用户的，大家直接通过对话的方式来使用AI产品，当然也有一些第三方开发者通过调用大模型厂商的API来提供产品服务，也就是大家提到的各种套壳（我不觉得套壳有啥问题，因为大模型的特性决定了，绝大部分的产品本质就是套壳，）

来举一些例子方便理解

- GPT是openAI开发的AI大模型，chatGPT是openAI开发的AI产品
- 文心大模型是百度开发的大模型，文心一言是百度开发的AI产品
- 混元大模型是腾讯开发的大模型，元宝是腾讯开发的AI产品
- Moonshot是月之暗面开发的大模型，kimichat是月之暗面开发的AI产品，“哄哄模拟器”是其他人基于Moonshot开发的AI产品
- … …

最后用一个比喻（某大佬写的）来帮助大家进一步的理解这个里面的差异

AI大模型是一个手中没有任何工具的人，你除了和它对话和思考（使用它脑内的知识），它无法帮你做任何其它的事情。但是，你可以将一些自己需要的工具（比如 Excel、搜索引擎）放到它的手上，这个时候它就能按照你的要求行动。

AI产品是一个被厂商在手里塞满了固定工具的人，它除了对话和思考，还可以使用厂商规定的功能帮你完成一些任务。但由于成本和安全的限制，一般厂商会在它的思考能力、输出能力和能使用什么工具上有所限制。

所以为什么一些AI产品不能批量处理表格数据，因为很多AI产品都只是通过对话的方式来处理一些请求，而批量处理表格需要循环的调用工程化的能力来进行数据处理

为什么有些产品没办法把整本书放进去，因为AI产品为了成本和性能的考虑会限制用户输入的内容长度，导致没办法读取完整的内容

为什么有些AI产品没办法回答一些最近发生的事，因为AI大模型本身不是搜素引擎，同时对应的应用可能没有让AI大模型去调用搜索引擎这些工具，就会导致没办法回答或者回答错一些时事相关的内容

AI和AI产品也有非常明显和优劣势和受众群体上的差异

AI产品的门槛更低，大部分时候我们可以直接使用，但是使用的时候又可能受限制于厂商从成本、目标等角度考虑设定的一些限制，存在一定的局限性

AI的门槛明显更高，需要你有一定的开发能力才能调用API，当然也就带来了更多的灵活性和可能性，你可以自己尝试去构建一些AI应用实现当前可能更多AI产品没办法实现的效果

比如我们可以自己动手构建一个基于主题生成图片的小助手，比如下面这个coze的小助手就可以帮助我在任何需要插图的地方直接输入相关内容就获得一些AI生成插图效果

![](https://my-image.askcheng.xyz/cheng-img/2024/07/7fc5d522a7055bfeedb2a77dd12b2391.png)

同时通过了解这些AI大模型和产品的差异帮助我们基于自己的实际场景来选择合适的工具，比如我们是一些搜索类型的问题，则可以尝试用AI搜索类型的产品来获得更好的回答

如果你有一定的动手能力，还可以基于第三方一些平台，比如coze、dify、n8n等平台来创作一些小工具，帮助自己完成一些日常工作中可能很繁琐枯燥的工作。（不用担心，在AI时代自己构建一个小工具的门槛被极大的降低了，你可以跟AI助手一起来协助你完成工具的构建，享受创作者的快乐）

# LLM的具体逻辑

![](https://my-image.askcheng.xyz/cheng-img/2024/07/150c7dca9c51e9a404d200cb1cc22c54.png)

AI大模型是基于海量数据进行训练的大参数量的模型，到底它是怎么通过回答一些用户的问题，这也是一个我们需要去理解的可能存在误区的地方

首先大家看到AI大模型好像可以回答我们各种问题，天然就会觉得那应该跟搜索引擎很像，好像问什么都可以检索到的感觉，这其实是一个非常大的误区。

**LLM不是搜索引擎，没有所有的数据库的概率，所谓的训练用到的数据是指的会用很多数据来做训练的，但是在回答你的问题的时候其实哪些数据已经没有关系了，也就是所谓的训练和推理是分离的，数据是构建大模型能力的重要组成部分，但是并不存在于大模型本身**

那LLM到底是什么呢？首先它是一个预训练之后的两个文件，预训练的意思就是它需要先闭关修炼提前训练，通过海量的数据和算力来学习这些数据里面可能存在的规律，然后通过参数文件来存储下来，比如下面就是llama 2 70B训练完成之后部署的两个文件，一个记录参数信息，一个启动文件，注意这个里面没有任何它训练时候用到的相关数据的信息

![](https://my-image.askcheng.xyz/cheng-img/2024/07/941ceabf377b6261943aff957f4fa287.png)

如果不是检索数据库，那大模型到底是怎么工作的呢？大模型的本质就是基于用户的输入在持续的进行概率预测，就是你前面输入的信息会持续被传入大模型进行后续可能出现的内容的预测，然后输出最终的结果，有点像成语接龙，基于全面的词持续的输入后面的内容

可以尝试这么理解，就是一个刷了很多很多很多题的高材生，然后能回答你一些高级的问题。但是这个里面就存在一个问题，就是他到底是真的懂了所谓的数学还有物理规律能做出来这些题，还是只是刷太多了所以自己就会了？这也是当前AI技术上存在争议的点，就是虽然看上去好像能回答我们的问题，但是其实并不是跟人类思考一样通过逻辑推理在回答

这里可以在稍微引申一点，有些偏技术性，涉及到大模型具体训练的过程和相关技术，不太感兴趣的同学可以跳过

---

之前有看到过一个观点，就是大模型在完成第一步的预训练没有进行后续的RLHF对齐的时候可能是更强的，怎么理解呢？

就是预训练其实就是大模型基于我们真实世界的数据的一个压缩，通过压缩的方式找到可能存在的规律，RLHF有个问题就是会往人类的偏好上去牵引，就好像有个人学会了各种技能和能力，但是你只用考试来评估他，因为你只懂考试的逻辑

这个里面存在一种可能性，就是人类是不是也并没有把自然界的所有规律都总结出来，现在我们理解AI，只能用我们已经提炼的一些基础知识比如数学、物理等等来理解，那有没有可能人类提炼的知识和认知限制了我们去理解大模型本身，甚至是在迁就我们自己

第一步预训练之后大模型，它在认知上其实可以近似理解成对所有训练数据的校准，没有任何的偏见足够全面，但是基于RLHF，特别是基于人类的反馈之后，它就会变得有些讨好你的感觉，有点过于谄媚，就是目的性非常强，为了考试进行的学习的过程的感觉

当然这个过程是必不可少的，我们需要去保证安全性，同时如果不对齐人类的认知的话，我们也没办法更好的理解和使用，但是不可否认可能这个过程也让大模型失去了更多的多样性和创造性

---

# 总结一下

最后我们来总结一下，首先AI和AI产品是两码事，我们在使用AI产品时碰到的很多局限性都跟厂商在构建的时候有关系，同时AI大模型本身也是一种特殊的技术形式，实现逻辑与我们理解的传统搜索引擎不一样，当让可以构建一些AI产品来使用搜索引擎的能力，就是我们碰到的这些问题，其实都是有对应的解决方案的

那可能有同学要问了，我又不是学技术的，我为什么要去理解和了解这些差异？

确实从用户和产品视角来讲，不应该要求所有人都能理解所谓的大模型的技术逻辑是什么？有什么差别等等？毕竟这些门槛和认知上的差异就是需要更多的产品经理来进行各种产品创新，降低用户的理解和使用门槛，一个好的产品确实应该就是永远不会让用户犯错，也不一定让用户难以理解和使用

但是AI大模型相关的技术还是太新了，我们还需要更多的时间才能看到更多的产品，以及随时技术的进展持续的降低大家使用的门槛，那在这个技术的早期，**先上路的人永远会有更多的主动权，本质上也只是一个选择罢了**

你理解了这些差异之后，你就不会在看到所有人都看到模型出糗的时候（比如搞不清楚9.9还是9.11的大小）也去围观去吐槽，而是基于自己当前工作的场景和问题去使用一些AI产品，去尝试构建提示词，去选择合适的工具，去构建一些小的工具和应用来帮助自己更加高效的工作生活，去创造一些更有价值的事情。