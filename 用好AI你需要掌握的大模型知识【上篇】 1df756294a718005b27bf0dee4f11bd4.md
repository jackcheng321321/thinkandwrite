# 用好AI你需要掌握的大模型知识【上篇】

> 这是我们 AI时代下项目管理系列文章的第一篇，也是关于技术解析的第一部分的内容，我们将分成两篇来介绍用好AI我们需要掌握那些大模型的知识
> 

如果你对于我们这个系列内容感兴趣，欢迎关注和转发~

用好AI本质其实一个**与AI进行高效协作**的过程，如果我们把个人AI模型和工具比作一个个的人的话，我们可以想一下最重要是不是就是去了解你的这些“协作对象”具体能做什么，不能做什么，擅长什么，不擅长什么

而且这些队友还都很强大，你问的任何问题都有答案，但是**答案的质量跟你提出的问题和指令的质量是息息相关的**，所以这个时候反而对于我们每个人提出了更高的要求

理解AI的运作方式并且掌握一些提问和协作的技巧，就是实现高效协作，最大化AI价值的基础

所以我们接下来介绍的内容会完全围绕**每个人实际使用AI的角度**出发去介绍一些大模型相关的知识，如果你对某些技术的细节感兴趣，但是我们可能没有涉及到的话，可以留言随时与我们进行更多的讨论和交流

![](https://my-image.askcheng.xyz/cheng-img/2025/04/f69dd9230c237a93af1a68143ec99866.png)

# AI是基于海量数据“学习”模式，而非真正“思考”

大模型是基于海量的数据先进行预训练，然后好像掌握了给的数据资料的一些规律。可以近似理解成一个人可能阅读了海量的古代诗词内容，而且是重复阅读了好多次，你让他来给你作一首诗，他也可以作的有模有样的，但是他并不知道他作的诗是什么意思，他只是形成了类似肌肉记忆，就像我们有时候如果有些内容已经背诵太多次了，某个人如果开了个头之后，你就无意识的开始背诵了，你可能都不知道你说的是什么意思

**所以大模型本质就是用了很多的数据训练，然后好像“学习”了人类数据中的一些规律，然后基于你的问题，开始基于概率进行持续的预测**

![](https://my-image.askcheng.xyz/cheng-img/2025/04/4632f34a1cd7537e8018e80de9dde88c.png)

基于概率的预测，所以大模型的回答就是有随机性的，你就算问的一模一样的问题，也可以获得不一样的答案。这里的不一样是指的，两次提问不可能每个字都完全一致。所以基于这个特性，我们也无法去溯源到底是哪里不对，我们只能多次重复去尝试找到一次合适的答案

基于概率的预测，决定了大模型没有所谓的自主意识，可能很多人都喜欢问“你是谁”之类的问题，其实是陷入了“过度拟人化”的陷阱，大模型的表达很人很像，你以为是一个人，但是其实不是，你问了这个问题之后，大模型也还是基于自己训练的数据找到的一些“规律”来接着回答这个问题，而不是真的在“思考”他是谁，大模型没有所谓的真正的“思考”

基于概率的持续预测，所以大模型是“无情”不是“中立”，在模型训练阶段会引入人类的观点对于模型的输入进行对齐，就是对于模型的输出打分来让模型看上去更加安全、友好等等。所以模型的回答是有“偏见的”，比如有些大模型可能会过度讨好用户，只要用户说不对，马上就修改回答，其实真实的情况是，大模型可能并不知道自己回答的对错，或者没有所谓的对错的概率。为什么你一质疑，它就道歉呢，根本原因是大模型在对齐的时候被调教得尽量友好而已。所以我们需要警惕一些情绪上的引导陷阱，不要因为模型的表达看上去很真诚，我们就盲目相信，需要自己有独立的思考和判断

**大模型不是搜索引擎，没有数据库！大模型不是搜索引擎，没有数据库！大模型不是搜索引擎，没有数据库！**

![](https://my-image.askcheng.xyz/cheng-img/2025/04/941ceabf377b6261943aff957f4fa287.png)

上面的图就是大模型训练完成之后的文件，主要是第一个参数文件，第二个是一个启动这个程序的文件，前面的参数文件是140GB的大小，里面如果你可以打开的话，其实就是无数的0、1

这个大模型的名字是llama2-70b，是meta训练完成的一个开源模型，开源模型的意思就是所有人都可以把这个模型下载到自己的服务器或者电脑上，只要你有足够好的GPU算力把它运行起来

70b指的是这个模型的参数量是70 billion，就是700亿个参数，对应的参数文件是140GB的大小，这个模型训练使用的数据大概是15T的数据

所以训练数据和模型参数是两码事，训练的数据是我们知道的各种互联网数据、书籍等等各种海量的数据，但是这个数据在训练之后，**模型保存是参数文件，不是训练的数据**

参数文件可以类比成对于训练数据的抽象和压缩，我们在具体使用大模型的时候，跟训练数据已经没有直接的关系了，是**大模型的参数基于我们的输入来进行基于概率的持续预测**

所以大模型不是搜索引擎，也不是知识库，看上去能基于训练的数据来回答问题是通过参数压缩和抽象来实现的，不是直接去检索的原始训练使用的数据，**模型训练完成之后，用户实际使用的时候就跟之前的训练数据没关系了**

![](https://my-image.askcheng.xyz/cheng-img/2025/04/aef9df672f2b27a8fb44cde067b8bb3f.png)

**大模型能回答训练数据里面提到的内容，不是真的有记忆，只是看过很多次，所以给用户的感觉是记住了**

# AI是“博学”，不是“全知全能”

由于大模型预训练的机制，所以大模型在回答问题的时候会有时效性的问题，因为训练使用的数据里面并不包括最新的一些信息和资料，所以大模型是博学，但不是什么事情都知道，一些最新发生的事情可能就是无法正确回答的

同时大模型训练使用的数据是一些书籍、互联网资料等等，所以一些个人和企业信息就可能是不知道的，比如你的一些基本信息如果互联网上没有出现过的话，你问大模型是不可能回答正确的。比如你问你的名字相关的新闻，如果你不是什么名人之类的，跟你在互联网上搜索你的名字的效果是类似的，不太可能找到你觉得正确的信息

所以如果你的问题是在当前互联网都不太可能找到正确答案的话，可能大模型也是无法正确回答的，**毕竟大模型没见过的内容，不太可能正确回答**

![](https://my-image.askcheng.xyz/cheng-img/2025/04/6233e02cbb7e0dd79b3c4f17991ae63d.png)

即使你的问题是在互联网上出现过的，也不代表就一定能准确的回答。第一个原因是我们前面已经提到过的模型是基于概率在持续预测，第二个原因则是因为训练数据的分布也会决定回答的效果

比如某个数据在训练数据里面出现过很多次，比如北京是中国的首都这种信息，那么答对的概率就大很多，而出现很少的就不一样的。就像你背书一样，如果一个课文或者一句话反复出现，那你回答正确的概率就一定会大很多

同时不同的语料数据做训练过程中的权重也是不一样的，比如维基百科就比一个普通的博客的内容权重高，权重高那么在训练的时候可能被记住的概率变高，因为权重高的在训练的过程中会被反复使用

所以对于我们提出的问题，我们需要有几个基础的判断，基于问题在互联网上出现的概率和频次能基本判断模型回答错误的概率

![](https://my-image.askcheng.xyz/cheng-img/2025/04/fdf2c26a6201172c59ac82f879d67390.png)

# 实际场景问题和解决方案

基于以上两点，我们来看看这些认知的误区可能带来的一些问题和对应的解决方案

1. 提问的问题是最近发生的

比如你问一个时效性非常高或者还未发生的问题，大模型会一本正经的回答你，但是其实是在胡编乱造

![](https://my-image.askcheng.xyz/cheng-img/2025/04/f399dbcf9f8af58b7afc12d7f1976047.png)

**解决方案：联网检索**

关于联网检索的逻辑我们后面在跟大家详细解释，可以简单理解成大模型在回答你之前，先去互联网上基于你的问题搜索了一下，然后结合搜索到的内容来回答你的问题，这样准确率就高了很多

现在很多AI产品都基本有联网检索功能，如果你的问题是这种类型的，则需要把联网检索功能打开，有些AI产品可能没有对应的 联网检索功能的开关，一般可能是模型自己去判断这个问题是否需要检索，你也可以直接在问题里面要求，比如“帮我联网检索一下XXXXX，然后回答我”’

基于联网检索回答的问题，最大的特点是回答内容的最后会有具体引用的数据源的网址，一般有来源的显示，则代表这个问题是联网检索回答的

1. 问的问题比较模糊

你希望了解某一个具体的概念，但是你提问的时候并没有说清楚具体的是什么行业或者场景下的，可能就会导致回答的结果不及预期

比如你问  PM应该怎么高效的开展工作？这个问题可能会导致歧义的地方在于PM可能是项目经理，可能是产品经理，如果你按照你自己的理解觉得是项目经理，而大模型按照产品经理来回答的话，你就会觉得效果不好了，而这其实本质是提问的问题

**解决方案：清晰的表达**

所以我们提出的问题需要尽量清晰，不要有理解上的歧义，因为你和大模型的交互完成就是你输入的那几个文字展开的，如果你的文字是不清晰的，是很容易导致你们在交流协作上出现问题的

关于这部分内容，我们会在后续关于提示词的部分在详细展开

![](https://my-image.askcheng.xyz/cheng-img/2025/04/57dee907b5e9ceb74a8fd4b87a570809.png)

---

这就是我们关于用好AI你需要掌握的大模型知识【上篇】的全部内容啦，如果你觉得内容对你有帮助，欢迎多多点赞、转发~

同时也非常欢迎大家在留言区跟我们交流，今天的内容对于你使用大模型有哪些帮助？你有没有重新尝试去问一些之前答案不好的问题？你在使用大模型的时候还碰到了哪些具体的问题？