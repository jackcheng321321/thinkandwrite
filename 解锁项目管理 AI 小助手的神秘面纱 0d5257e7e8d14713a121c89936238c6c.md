# 解锁项目管理 AI 小助手的神秘面纱

> 我们相信我们在某些具体场景下碰到的问题，其他人都碰到过，也很好的解决过，并且还进行了总结和归纳，这些答案都存在各种书籍中。所以基于各种项目管理相关的书籍，构建了一个AI助手，能在我们碰到相关问题的时候解答我们的问题，给我们更多的信息视角。
> 

<aside>
💡 **AI助手更多的是帮助我们能更好的回忆和检索一些书籍中的标准答案，给我们更多的启发，但是没办法替代我们思考**

</aside>

# 基础介绍

AI助手主要是基于字节的coze平台构建的，访问地址：https://www.coze.cn/home（免费的，至少暂时是的）

![微信图片_20240708192741.png](%25E5%25BE%25AE%25E4%25BF%25A1%25E5%259B%25BE%25E7%2589%2587_20240708192741.png)

有三种方式可以访问和使用这个AI小助手

1. 通过coze的官方商店：https://www.coze.cn/s/i6sDnrsE/
2. 通过字节的豆包app:https://www.doubao.com/chat/74828932434946
3. 直接通过我们公众号“项目管理跃迁”在后台提问就可以了，不过公众号会有些限制，所以体验可能不太好

这个AI助手会根据用户输入的相关问题检索一些相关的书籍中的相关片段，然后来给用户一个合适的回答，我们可以提问一些比较泛的问题，比如“怎么有效的进行需求管理？”

![CozeIMG.png](CozeIMG.png)

也可以针对你当前所处的场景，来提出具体的问题，比如“新到一个项目上，怎么有效的指定项目管理的流程和制度？”

![CozeIMG (1).png](CozeIMG_(1).png)

AI助手不一定能很好的对你提出的问题给出非常精准的回答，但是至少可以给你当前所面对的问题给出一些更多的视角和建议，帮助你思考你所面对的问题的更加合适的解决方案

当然AI助手是可以持续追问的，所以我们也可以针对某个具体的问题进行持续的提问，获得更好的回答和反馈（微信公众号可能不太能支持连续的追问）

当然如果你对于提问之后的回答有更多的诉求或者有更多需求，也可以在相关平台进行反馈

# 具体搭建流程

> 授人以鱼不如授人以渔，希望通过这个搭建流程的说明让大家也都可以尝试去构建一些AI助手来帮自己和团队提高工作效率
> 
1. 通过https://www.coze.cn/ 注册一下账号，登录之后，点击个人空间会看到相关信息

![微信图片_20240708194017.png](%25E5%25BE%25AE%25E4%25BF%25A1%25E5%259B%25BE%25E7%2589%2587_20240708194017.png)

1. 我们这个场景下需要关联一些自己已有的数据，所以需要先进入到知识库的功能中，进行私有数据的创建，打开知识库后，点击右上角的新建知识库

![微信图片_20240708194353.png](%25E5%25BE%25AE%25E4%25BF%25A1%25E5%259B%25BE%25E7%2589%2587_20240708194353.png)

- 当前平台是支持三种格式的，文本、表格和照片，但是其实检索的时候的逻辑是一样的，表格数据的每一条数据都会变成单独的一条数据记录，照片也是会把图片中的相关信息转换成文本，最终检索效果都是基于用户输入的问题与已有数据的关联性进行检索的
- 导入类型支持本地文档、在线数据、Notion、飞书和自定义，大家根据自己的数据情况来选择即可，飞书和Notion以及在线数据是支持自动更新的，但是数据本身也需要一些授权和限制，可以选择具体数据类型查看
- 图标有默认值，也可以根据名称AI生成

1. 数据导入相关配置
- 导入数据需注意平台的一些限制

![微信图片_20240708194826.png](%25E5%25BE%25AE%25E4%25BF%25A1%25E5%259B%25BE%25E7%2589%2587_20240708194826.png)

- 上传了相关文件后，会有一个分段设置，不清楚的话可以直接选择自动，如果自己的数据有一些特殊的格式，比如会通过一些特殊符号来分段，则可以选择自定义（数据分片的情况会非常影响最终效果，后续可以根据具体表现来调整分片规则）

![微信图片_20240708195218.png](%25E5%25BE%25AE%25E4%25BF%25A1%25E5%259B%25BE%25E7%2589%2587_20240708195218.png)

1. 最后等待数据处理完成，我们就可以去创建自己的bot了，新建后进入bot的构建页面

![微信图片_20240708195431.png](%25E5%25BE%25AE%25E4%25BF%25A1%25E5%259B%25BE%25E7%2589%2587_20240708195431.png)

- 左侧进行提示词的构建，不要怕，你可以先简单写一下你的基础需求，然后点击右上角的AI优化按钮，就会获得一个还不错的提示词了，不过也需要注意，AI优化后可能会衍生出来很多我们不太需要的能力和要求，你在基于你自己的需求进行适当的删减和编辑就可以了
- 中间的知识部分，点击添加去关联我们前面导入的知识库内容就可以了，文本和表格以及照片是不同的入口，支持关联多个
- 知识内容支持选择调用方式，默认是自动调用，建议保持默认配置，如果后续有更加个性化的需求可以在进行进一步的调整，同时如果期望回答的内容显示具体的知识来源则可以勾选显示来源，同时如果用户输入的内容没有检索到关联信息时，可以配置固定回复或者由大模型自己来回复

![微信图片_20240708200032.png](%25E5%25BE%25AE%25E4%25BF%25A1%25E5%259B%25BE%25E7%2589%2587_20240708200032.png)

1. 完成之后，你就可以在右侧进行预览和调试啦，如果效果有不满意的地方就可以持续的进行调整，同时你还可以配置一些开场白和预设问题，帮助用户更好的了解你的机器人是用来干什么的

![微信图片_20240708200640.png](%25E5%25BE%25AE%25E4%25BF%25A1%25E5%259B%25BE%25E7%2589%2587_20240708200640.png)

1. 调试好了之后，就可以点击右上角的发布，让更多人可以通过商店、豆包或者其他方式来使用你创建的机器人了

![微信图片_20240708200804.png](%25E5%25BE%25AE%25E4%25BF%25A1%25E5%259B%25BE%25E7%2589%2587_20240708200804.png)

最后整个coze平台的功能比较复杂，能实现的效果也非常多，如果对于其他的相关能力也感兴趣的同学，可以自己去查看官方的帮助文档和一些相关社区的教程，**当然最重要的还是自己上手去操作，感受整个创作的过程**

# 发散一下

除了我们上面举的例子，知识库机器人还可以用在非常多的场景下

- 比如我们可以基于这个逻辑来构建一个产品说明机器人，特别是那些有很多sku情况以及产品整体参数和介绍复杂的产品 ，我们都可以快速构建AI助手来帮助我们回答产品相关的问题
- 比如有些项目管理的流程比较复杂，涉及到很多的步骤和细节，我们也可以通过构建机器人的方式来帮助团队成员随时回答流程上的问题，释放项目经理的精力，让我们能关注到更加重要的事情上

上面是一些知识库机器人的场景，基于coze这种构建平台，我们还可以发挥我们的想象力，构建更多的AI助手来帮助我们提高工作和学习效率

- 比如我们有各种学习和考试的需求，则可以构建一个学习考试的助手，来回答我们一些教材上的内容，设置直接基于相关的内容来出一些模拟题目都可以
- 比如我们可能面对各种场景都提前进行场景模拟，模拟一个面试官出来提前进行面试的演练，模拟一个用户出来进行需求调研等等

<aside>
💡 **AI是放大器，放大的是我们的每一个创意**

</aside>

# 技术科普

最后我们还是对这种知识库机器人的基础技术逻辑做个简单的科普，对于这个技术本身的认知能更好的帮助我们使用AI，获得更加高效的使用体验

这些知识库机器人的实现逻辑本质是一个叫RAG的技术，全称是检索增强生成（Retrieval Augmented Generation），是一种结合了检索模型和生成模型的技术。它通过从大型数据集或知识库中检索相关信息，并将这些信息作为上下文提供给生成模型，从而生成更准确、相关和多样化的自然语言响应。

用一张图来简化的表达一下RAG具体的意思，帮助大家理解（注意是极简版本，整个过程中还会涉及到非常多的细节和流程）

![微信图片_20240708202827.png](%25E5%25BE%25AE%25E4%25BF%25A1%25E5%259B%25BE%25E7%2589%2587_20240708202827.png)

1. 首先用户的提问会先去进行内容检索（**注意这部分跟大模型没关系**），如果我们检索的是知识库，那就是一个知识库机器人，如果我们检索的是搜索引擎的数据，那就是一个AI搜索产品的效果
2. 检索出来的结果会跟用户的提问放到提示词里面一起给到大模型推理， 推理的意思可以理解成**你给了一个问题和问题相关的参考片段给一个考生，然后让这个考生用自己的语言总结和归纳一下，这个问题合适的答案是什么，我们也可以把RAG叫做开卷考试，本质用的大模型的推理能力，不是让他自己用它原生的知识和能力来回答这个问题**
3. 基于逻辑推理之后的结果回复给用户

基于上面的这个简单的过程，我们会发现几个信息

- 本质上RAG还是通过提示词的方式来完成回答的过程，这也是之前提到过的提示词是跟大模型唯一交互的方式
- 避免幻觉最低成本和有效的方式就是通过RAG，毕竟这个时候我们其实用到的大模型的能力是语义理解和一点点的逻辑推理能力，并没有用大模型自己的知识和数据，就可以有效的规避模型本身的幻觉问题
- 最后这个过程其实有非常多细节，比如数据入库的时候我们需要分片（因为本质还是把各种数据作为提示词给到大模型的，大模型是有上下文长度限制的，所以我们需要切片来控制参考内容的长度），怎么分片、怎么构建索引、怎么进行数据的检索、怎么召回相关的片段、怎么进行召回数据的排序、怎么进行最终提示词的构建，这些都会影响最终的回答效果，所以是个复杂的工程问题